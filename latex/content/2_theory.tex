\section{Theory}
The following section describes the derivation of the method written in B. Sch√∂lkopf and A. J. Smola, \textit{Kernel principal component analysis}\cite{scholkopf1997kernel}.

The Kernel Principal Component Analysis allows us to find Principal Components which are nonlinearly related to the input space. Giving the possibility to extract and find relevant data having a nonlinear relation in the input space.

%This statement is not accurate, so i have taken the introduction to 2.2 up here instead - Agnes
%The advantage of this method rely in its performances when performing PCA on high-dimensional data, even if these data have been generated using a non-linear transformation from their initial space by the use of a kernel function. Therefore, it should give better result than standard PCA (using maximizing variance or minimum squared distance criteria\footnote{TODO: check if correct}) when applied to such a dataset.

\input{content/2_1_concepts}

\input{content/2_2_kernel_pca}
